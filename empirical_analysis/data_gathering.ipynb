{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook used for constructing the datasets used in the empirical section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) historical Standard & Poors 500 constituents dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 70/820 [04:17<27:33,  2.21s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not add ACE"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 306/820 [15:45<15:31,  1.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not add RE"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 635/820 [35:01<04:54,  1.59s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not add CDAY"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 758/820 [41:31<01:58,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not add LDW"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 820/820 [44:59<00:00,  3.29s/it]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os \n",
    "with open(\"fmp_key.pkl\", \"rb\") as input_file:\n",
    "  fmp_key = pickle.load(input_file)\n",
    "\n",
    "with open(\"eod_key.pkl\", \"rb\") as input_file:\n",
    "  eod_key = pickle.load(input_file)\n",
    "\n",
    "import urllib, json\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "# Function to get the Data\n",
    "\n",
    "def get_jsonparsed_data(url):\n",
    "    res = urlopen(url)\n",
    "    data = res.read().decode(\"utf-8\")\n",
    "    return json.loads(data)\n",
    "\n",
    "import datetime as dt\n",
    "from tqdm import tqdm \n",
    "\n",
    "filename = 'price_df.csv'\n",
    "data_provider  = 'eod' # other choice is 'fmp'\n",
    "\n",
    "# first look up the historical s&p 500 constituents\n",
    "constituents = get_jsonparsed_data(\"https://financialmodelingprep.com/api/v3/historical/sp500_constituent?apikey={}\".format(fmp_key))\n",
    "constituents = pd.DataFrame(constituents)\n",
    "constituents['date'] = pd.to_datetime(constituents['date'])\n",
    "all_tickers = set(constituents['symbol'].values)\n",
    "\n",
    "begin = dt.datetime(1980,1,2)\n",
    "end   = dt.datetime(2024,1,1)\n",
    "\n",
    "price_df = pd.DataFrame(index=pd.date_range(start=begin, end=end, freq=\"B\"))\n",
    "failed_to_add = list()\n",
    "# check if the file already exists\n",
    "if os.path.exists(filename):\n",
    "    price_df = pd.read_csv(filename)\n",
    "    price_df = price_df.rename(columns={'Unnamed: 0':'date'})\n",
    "    price_df.set_index('date', inplace=True)    \n",
    "\n",
    "for count, ticker in enumerate(tqdm(all_tickers)):\n",
    "    # find the correct dates the stock was part of the s&p 500\n",
    "    date_begin = begin\n",
    "    date_end   = end\n",
    "    ticker = ticker.split(\" \")[0]\n",
    "    \n",
    "    if ticker in price_df.columns:\n",
    "        continue\n",
    "    for _, row in constituents[constituents.symbol == ticker].iterrows():\n",
    "        if len(row['addedSecurity']) != 0:\n",
    "            date_begin = begin if row.date <= begin else row.date\n",
    "        if len(row['removedSecurity']) != 0:\n",
    "            date_end = end if row.date >= end else end\n",
    "\n",
    "    if data_provider == 'fmp':\n",
    "        # get the data from the fmp api\n",
    "        df = get_jsonparsed_data(\"https://financialmodelingprep.com/api/v3/historical-price-full/{}?from={}&to={}&apikey={}\".format(ticker,\n",
    "            date_begin.strftime('%Y-%m-%d'),date_end.strftime('%Y-%m-%d'),fmp_key))\n",
    "        if len(df) == 0:\n",
    "            print('could not add {}'.format(ticker),end=\"\")\n",
    "            failed_to_add.append(ticker)\n",
    "            continue\n",
    "        df1 = pd.DataFrame(df['historical'])\n",
    "        df1['date'] = pd.to_datetime(df1['date'])\n",
    "        df1.set_index('date',inplace=True)\n",
    "        # merge the dataset\n",
    "        price_df = pd.merge(price_df, df1['adjClose'], how='left', left_index=True, right_index=True)\n",
    "        price_df = price_df.rename(columns={'adjClose': ticker})\n",
    "    elif data_provider == 'eod':\n",
    "        df  = get_jsonparsed_data(\"https://eodhd.com/api/eod/{}.US?from={}&to={}&period=d&api_token={}&fmt=json\".format(ticker,\n",
    "            date_begin.strftime('%Y-%m-%d'),date_end.strftime('%Y-%m-%d'), eod_key))\n",
    "        if len(df) == 0:\n",
    "            print('could not add {}'.format(ticker),end=\"\")\n",
    "            failed_to_add.append(ticker)\n",
    "            continue\n",
    "        df1 = pd.DataFrame(df)\n",
    "        df1['date'] = pd.to_datetime(df1['date'])\n",
    "        df1.set_index('date',inplace=True)\n",
    "        # merge the dataset\n",
    "        price_df = pd.merge(price_df, df1['adjusted_close'], how='left', left_index=True, right_index=True)\n",
    "        price_df = price_df.rename(columns={'adjusted_close': ticker})\n",
    "\n",
    "    # occasionally backup the dataframe\n",
    "    if count % 20 == 0:\n",
    "        price_df.to_csv(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
